# EchoVision
This project uses EfficientNetB0 to classify human actions based on sequences of images captured from a live camera feed. The model processes multiple frames to recognize actions such as calling, dancing, running, and more. It provides real-time audio feedback with a friendly voice, enhancing accessibility and user interaction.
